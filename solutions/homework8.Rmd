---
title: "Homework 8"
author: "Andrei Dmitrenko"
date: "April 17, 2019"
output:
    pdf_document:
html_document:
df_print: paged
---

# Task 27

## Classical NEMs

### 1. Finding expected effect patterns:  

```{r}
# define Phis for 2 graphs
Phi.1 = matrix(rep(0,25), nrow = 5, ncol = 5)
Phi.2 = matrix(rep(0,25), nrow = 5, ncol = 5)

# hardcoding edges
Phi.1[1, c(1,2,3)] = 1
Phi.1[2, c(2,3,5)] = 1
Phi.1[3, c(3,5)] = 1
Phi.1[4, c(4,5)] = 1
Phi.1[5, 5] = 1

Phi.2[1, c(1,3)] = 1
Phi.2[2, c(1,2,3,5)] = 1
Phi.2[3, c(3,5)] = 1
Phi.2[4, c(4,5)] = 1
Phi.2[5, 5] = 1

# define Thetas for 2 graphs
Theta.1 = matrix(rep(0,30), nrow = 5, ncol = 6)
Theta.2 = matrix(rep(0,30), nrow = 5, ncol = 6)

# hardcoding edges
Theta.1[2, c(1,2)] = 1
Theta.1[3, c(3)] = 1
Theta.1[4, c(4,6)] = 1
Theta.1[5, c(5)] = 1

Theta.2[1, c(1,2)] = 1
Theta.2[3, c(3)] = 1
Theta.2[4, c(4,6)] = 1
Theta.2[5, c(5)] = 1

# computing effect patterns
F.1 = Phi.1 %*% Theta.1
F.2 = Phi.2 %*% Theta.2

colnames(F.1) = c("E1", "E2", "E3", "E4", "E5", "E6")
rownames(F.1) = c("S1", "S2", "S3", "S4", "S5")
colnames(F.2) = c("E1", "E2", "E3", "E4", "E5", "E6")
rownames(F.2) = c("S1", "S2", "S3", "S4", "S5")

F.1
F.2
```

### 2. Finding transformation matrix A:  

```{r}
# finding transformation matrix
inversed.A = solve(Phi.1, Phi.2)
A = solve(inversed.A)
A
# check correctness
sum(A %*% Theta.1 == Theta.2) == nrow(Theta.2) * ncol(Theta.2)

```

### 3. Calculating the marginal likelihoods:  

```{r}
library("nem")

# applying nem to get mLLs
control = set.default.parameters(unique(colnames(t(F.1))), para=c(0.01, 0.01))
models.list = list(Phi.1, Phi.2)

res.1 = nem(t(F.1), models = models.list, control=control)
res.2 = nem(t(F.2), models = models.list, control=control)

# marginal likelihoods
res.1$mLL
res.2$mLL
```

# Task 28

## Hidden Markov NEMs

### 1. Computing the transition probabilities:  

```{r}
# define adjacency matrices
adj.matrix.u = matrix(rep(0,16), nrow=4)
colnames(adj.matrix.u) = c("S1", "S2", "S3", "S4")
rownames(adj.matrix.u) = c("S1", "S2", "S3", "S4")

adj.matrix.u[1, c(1,2,3,4)] = 1
adj.matrix.u[2, c(2,4)] = 1
adj.matrix.u[3, c(3,4)] = 1
adj.matrix.u[4, 4] = 1

adj.matrix.v1 = matrix(rep(0,16), nrow=4)
colnames(adj.matrix.v1) = c("S1", "S2", "S3", "S4")
rownames(adj.matrix.v1) = c("S1", "S2", "S3", "S4")

adj.matrix.v1[1, c(1,2,3,4)] = 1
adj.matrix.v1[2, c(2,4)] = 1
adj.matrix.v1[3, 3] = 1
adj.matrix.v1[4, 4] = 1

adj.matrix.v2 = matrix(rep(0,16), nrow=4)
colnames(adj.matrix.v2) = c("S1", "S2", "S3", "S4")
rownames(adj.matrix.v2) = c("S1", "S2", "S3", "S4")

adj.matrix.v2[1, 1] = 1
adj.matrix.v2[2, c(2,3,4)] = 1
adj.matrix.v2[3, 3] = 1
adj.matrix.v2[4, c(1,4)] = 1

# calculate distances
s.u.v1 = 0
s.u.v2 = 0
for (i in 1:nrow(adj.matrix.u)){
  for (j in 1:ncol(adj.matrix.u)){
    s.u.v1 = s.u.v1 + abs( adj.matrix.u[i,j] - adj.matrix.v1[i,j] )
    s.u.v2 = s.u.v2 + abs( adj.matrix.u[i,j] - adj.matrix.v2[i,j] )
  }
}

# get all possible graph structures
all.models = enumerate.models(c("S1", "S2", "S3", "S4"))

# define data structure to store transition probabilities
transition.probs = matrix(rep(0, 9*2), nrow=2)
colnames(transition.probs) = c("l=0.1","l=0.2","l=0.3","l=0.4","l=0.5","l=0.6","l=0.7","l=0.8","l=0.9")
rownames(transition.probs) = c("u->v1", "u->v2")

# calculate transition probabilities
for (lambda in 1:9){
  
  # calculate normalizing constant z.u for current lambda
  z.u = 0
  for (m in 1:length(all.models)){
    # calculate distance to graph structure m
    s.u.m = 0
    for (i in 1:nrow(adj.matrix.u)){
      for (j in 1:ncol(adj.matrix.u)){
        s.u.m = s.u.m + abs( adj.matrix.u[i,j] - all.models[[m]][i,j] )
      }
    }
    # add to the sum over all graph structures
    z.u = z.u + 0.1 * lambda * (1 - 0.1 * lambda) ** s.u.m
  }
  
  # calculate transitions probabilities for v1 and v2 for current lambda
  transition.probs[1, lambda] = (0.1 * lambda * (1 - 0.1 * lambda) ** s.u.v1) / z.u
  transition.probs[2, lambda] = (0.1 * lambda * (1 - 0.1 * lambda) ** s.u.v2) / z.u
}

transition.probs
```

### 2. Plotting transition probabilities:

```{r}
# plot probabilities
plot(1:9/10, transition.probs[1,], type="b", col="red", xlab = "Lambda", ylab = "Transition probabilities", xlim = c(0.1,0.9), ylim=c(0,0.1))
lines(1:9/10, transition.probs[2,], type="b", col="blue", lty=2)
legend("topright", legend=c("transition u -> v1", "transition u -> v2"), col=c("red", "blue"), lty=1:2)
```

With increasing the smoothing parameter the probability to make transition to $v_1$ grows up. This is because $v_1$ structure is less different from $u$ than $v_2$.  

# Task 29
 
## Mixture NEMs

### 1. Computing the perturbation map and the noiseless log odds matrix:  

```{r}
# define Phis for 2 graphs
Phi.F1 = matrix(rep(0,4), nrow = 2)
Phi.F2 = matrix(rep(0,4), nrow = 2)

# hardcode edges
Phi.F1[1, c(1,2)] = 1
Phi.F1[2, 2] = 1

Phi.F2[1, 1] = 1
Phi.F2[2, c(1,2)] = 1

# define Thetas for 2 graphs
Theta.F1 = matrix(rep(0,4), nrow = 2, ncol = 2)
Theta.F2 = matrix(rep(0,4), nrow = 2, ncol = 2)

# hardcode edges
Theta.F1[1, 1] = 1
Theta.F1[2, 2] = 1

Theta.F2[1, 2] = 1
Theta.F2[2, 1] = 1

# define perturbation map based on given data
ro = matrix(rep(0,8), nrow = 2, ncol = 4)
colnames(ro) = c("c1", "c2", "c3", "c4")
rownames(ro) = c("e1", "e2")

ro[1, c(1,3)] = 1
ro[2, c(2,3,4)] = 1

ro

# compute the expected effect patterns
expected.effects.F1 = t(t(ro) %*% Phi.F1 %*% Theta.F1)
expected.effects.F2 = t(t(ro) %*% Phi.F2 %*% Theta.F2)

# replace zeros by -1s (why?)
expected.effects.F1[expected.effects.F1 == 0] = -1
expected.effects.F2[expected.effects.F2 == 0] = -1

# combine expected effects to obtain log odds matrix R
R = cbind(expected.effects.F1[,1:2], expected.effects.F2[,3:4])

R
```

### 2. Calculating responsibilities:  

```{r}
# define mixture weights
pis = c(0.32, 0.68)
L1 = t(ro) %*% Phi.F1 %*% Theta.F1 %*% R
L2 = t(ro) %*% Phi.F2 %*% Theta.F2 %*% R
Ls = list(L1, L2)

# calculating responsibilities
responsibilities = matrix(rep(0,8), nrow = 2)
rownames(responsibilities) = c("F1", "F2")
colnames(responsibilities) = colnames(ro)

for (k in 1:2){
  for (i in 1:4){
    
    denominator = 0
    for (j in 1:2){
      denominator = denominator + pis[j] * exp(Ls[[j]][i,i])
    }
    
    responsibilities[k,i] = pis[k] * exp(Ls[[k]][i,i]) / denominator
  }
}

responsibilities
```

After binarizing is become clear, that cells 1 and 2 belong to $F_1$, cells 3 and 4 belong to $F_2$.  

```{r}
# round the probabilities
belongings = responsibilities
belongings[belongings >= 0.5] = 1
belongings[belongings < 0.5] = 0

belongings
```


